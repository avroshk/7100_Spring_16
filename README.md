# 7100_Spring_16
Spring 2016 Research Project - Speaker Identification - Tagging a stream of audio to respective speakers in a meeting. 

Motivation: To generate an automated note-taking system 

Use case: By identifying the audio snippets spoken by different individuals in a meeting, we can easily convert the audio associated with speakers to text and catalog them for minutes of the meeting. 

Scope:
Step1 - The initial focus of this project is on robust speaker identification without any prior training. The system should be able to detect new speakers and segregate it from different speakers it comes across during a meeting.
Step2 - Conversion of tagged audio to text 

Out of scope items that may be considered based on time constraints:
Step3 - Using language models to extract useful keywords and phrases from the logged text
Step4 - An app that actively listens to conversations during meetings and creates an automatic "minutes" that might serve as a source of information shared during the meeting.
